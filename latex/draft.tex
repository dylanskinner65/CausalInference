\documentclass{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{ntheorem}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\usepackage{tkz-graph}
\usetikzlibrary{arrows}
\usetikzlibrary{shapes.geometric}


\SetVertexNormal[Shape      = circle,
                 FillColor  = cyan,
                 LineWidth  = 2pt]
\SetUpEdge[lw         = 1pt,
           color      = black,
           labelcolor = white,
           labeltext  = red,
           labelstyle = {sloped,draw,text=blue}]
\tikzset{Bullet/.style={fill=black,draw,color=#1,circle,minimum size=3pt,scale=0.75}}


\begin{document}


\title{Causal Inference with Graphical Neural Networks}
\author{Your Name}
\date{\today}
\maketitle

\section{Introduction}


% Introduce the topic of causal inference with Graphical Neural Networks (GNNs).

\section{$\textbf{do}$ Operator}

The \textbf{do} operator is a way to represent interventions in a causal model. 
It is a way to represent the effect of an intervention on a variable. As an example, 
consider the following model involving smoking.

If a person's fingernails $(N)$ have turned yellow, this implies a higher probability 
that they are a heavy smoker $(S)$ and hence have a higher probability of developing 
lung cancer $(C)$. But, simply dyeing a persons fingernails yellow does not impact 
their probability of developing lung cancer. 

So, in terms of $\textbf{do}$ calculus, we can denote the process of setting a 
variable $N$ to have a value $\textit{yellow}$ by $\textbf{do}(N = \textit{yellow})$. 
We note that 

\begin{equation*}
P(C \;|\;N = \textit{yellow}) \neq P(C\;|\; \textbf{do}(N=\textit{yellow})).
\end{equation*}

With this in mind, we now define the $\textbf{do}$ operator.

\begin{theorem}[{{\cite{pearl2009causal}}}]
    In a causal diagram $\Gamma$ with nodes $X_1,\dots, X_n$ and joint distribution 
    $P(X_1, \dots, X_n)$, the result of doing $X_i = x_i$ on the joint distribution is

    \[
        P(X_1, \dots, X_n \;|\; \textbf{do}(X_i = x_i)) = \frac{P(x_1,\dots,x_n)}{P(x_i\;|\; \textup{par}(x_i))} = \prod_{j\neq i}P(x_j\;|\; \textup{par}(x_j)).
    \]
    \label{theorem:do}
\end{theorem}

In this, we have $\text{par}(x_i)$ represent values of the parent nodes of $\text{PAR}(X_i)$ of $X_i$ in $\Gamma$.
The probabilities on the right hand side of the above equation are what we call \textit{preintervention}. 
This means they use the original probabilities from the original model before doing $X_i = x_i$.

It is important to note that the above equation is how we calculate the probability of several events 
happening given one event has happened. What if we want to get the probability of a single event happening, 
given we do a single event? That leads to the following corollary.

\begin{corollary}
    If $X$ and $Y$ are random variables in a causal diagram $\Gamma$ and $\textup{PAR}(X)$ are the parents of $X$, then

    \[P(y\;|\;  \textbf{do}(x)) = \sum_{\textup{par}}\frac{P(x,\,y,\,\textup{par})}{P(x\;|\; \textup{par})},\]

    where the sum runs over all values $\textup{par}$ that the variables $\textup{PAR}(X)$ can take. If $X$ has no parents, then

    \[P(y\;|\; \textbf{do}(x)) = \frac{P(x,\,y)}{P(x)} = P(y\;|\; x).\]
    \label{corollary:do}
\end{corollary}

Let us now consider a basic example to see how this works. Consider the following causal diagram in Figure~\ref{fig:causal_dia}.

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[scale=1.5, Bullet/.style={circle, draw=black, fill=#1, inner sep=0pt, minimum size=3mm, line width=1.pt}]
        \node[Bullet=cyan,label=above :{$A$}] (A) at (0,2){};
        \node[Bullet=cyan,label=above :{$C$}] (C) at (4,2){};
        \node[Bullet=cyan,label=below :{$B$}] (B) at (2,1){};
        \node[Bullet=cyan,label=below :{$Y$}] (Y) at (4,0){};
        \node[Bullet=cyan,label=below :{$X$}] (X) at (0,0){};
    
        \draw[->, line width=1] (A) -- (B);
        \draw[->, line width=1] (C) -- (B);
        \draw[->, line width=1] (B) -- (X);
        \draw[->, line width=1] (C) -- (Y);
        \draw[->, line width=1] (A) -- (X);
    \end{tikzpicture}
    \caption{Basic causal diagram. Note it is in the form of a directed acyclic graph (DAG).}
    \label{fig:causal_dia}
\end{figure}

In this diagram, we can see that $A$ and $C$ are both parents of $B$. So, for any values of $x$ and $b$, 
Corollary~\ref{corollary:do} tells us that

\begin{align*}
    P(X = x \,|\, \textbf{do}(B=b)) &= \sum_{\text{par}(b)}\frac{P(x, \,b, \,\text{par}(b))}{P(b\,|\, \text{par}(b))} \\
    %  &= \sum_{a}\sum_{c}\frac{P(X=x\,, \, A=a\,,\, B=b \, ,\, C=c)}{P(B=b \;|\; A=a,\, C=c)} \\
    %  &= \sum_{a}\sum_{c}\frac{P(X=x\;|\; A=a\,,\, B=b)P(B=b\;|\; A=a,\, C=c)P(A=a)P(C=c)}{P(B=b \;|\; A=a,\, C=c)} \\
    %  &= \sum_{a}\sum_{c}P(X=x\;|\; A=a\,,\, B=b)P(A=a)P(C=c) \\
\end{align*}

which, written out, is 

\begin{equation*}
    \sum_{\text{par}(b)}\frac{P(x, \,b, \,\text{par}(b))}{P(b\,|\, \text{par}(b))} = \sum_{a}\sum_{c}\frac{P(X=x\,, \, A=a\,,\, B=b \, ,\, C=c)}{P(B=b \;|\; A=a,\, C=c)}.
\end{equation*}

By dependence of nodes only on their parents and the rules of probability, this turns into

\begin{equation*}
    \sum_{a}\sum_{c}\frac{P(X=x\;|\; A=a\,,\, B=b)P(B=b\;|\; A=a,\, C=c)P(A=a)P(C=c)}{P(B=b \;|\; A=a,\, C=c)},
\end{equation*}

which simplifies to

\begin{equation*}
    \sum_{a}\sum_{c}P(X=x\;|\; A=a\,,\, B=b)P(A=a)P(C=c).
\end{equation*}

Since there is only one instance where we are considering the probability with respect to $c$, 
we can simplify this to

\begin{equation*}
    \sum_{a}P(X=x\;|\; A=a\,,\, B=b)P(A=a),
\end{equation*}

which is our final answer.

While this introduction to the \textbf{do} operator might feel a bit abstract, it is the foundation
of all current research in causal inference. 

\section{Data}

For our project, we used the LUCAS0 dataset~\cite{lucas_dataset}, which is a toy data set 
generated artificially by causal Bayesian networks with binary variables. The LUCAS0 dataset
is a DAG with 11 nodes and 2000 training samples, where the DAG is represented as

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[scale=1.5, Bullet/.style={circle, draw=black, fill=#1, inner sep=0pt, minimum size=3mm, line width=1.pt}]
        \draw[help lines, gray] (0,0) grid (6,6);
        \node[ellipse, draw=black, fill=lime] (A) at (2,2){Anxiety};
        \node[ellipse, draw=black, fill=lime, align=center] (P) at (4,2){Peer\\Pressure};
        \node[ellipse, draw=black, fill=teal] (S) at (3,1){Smoking};
        \node[ellipse, draw=black, fill=lime, align=center] (Y) at (1,1){Yellow\\Fingers};
        \node[ellipse, draw=black, fill=lightgray, align=center] (B) at (6, 2){Born on\\Even Day};
        \node[ellipse, draw=black, fill=teal, align=center] (G) at (5, 1){Genetics};
        \node[ellipse, draw=black, fill=teal, align=center] (C) at (2, 0){Allergy};
        \node[Bullet=cyan,label=below :{$X$}] (X) at (0,0){};
    
        \draw[->, line width=1] (A) -- (S);
        \draw[->, line width=1] (P) -- (S);
        \draw[->, line width=1] (S) -- (Y);

    \end{tikzpicture}
    \caption{Basic causal diagram. Note it is in the form of a directed acyclic graph (DAG).}
    \label{fig:lucas_dag}
\end{figure}






\section{Background}

% Provide background information on causal inference, neural networks, and Graphical Neural Networks (GNNs).

\section{Methodology}

% Describe the methodology of using GNNs for causal inference. Include information on how GNNs are trained, how causal inference is performed, etc.

\section{Experiments}

% Present the experiments conducted to evaluate the performance of GNNs for causal inference. Include dataset descriptions, experimental setup, and results.

\subsection{Dataset Description}

% Describe the datasets used in the experiments.

\subsection{Experimental Setup}

% Explain the experimental setup, including model architecture, training procedure, hyperparameters, etc.

\subsection{Results}

% Present and analyze the results of the experiments. Include metrics, comparisons with baseline methods, and any insights gained.

\section{Discussion}

% Discuss the implications of the results, limitations of the approach, potential future research directions, etc.

\section{Conclusion}

% Summarize the key findings of the study and conclude the paper.

\section*{Acknowledgments}

% Acknowledge any individuals or organizations that contributed to the project.

% Bibliography
\bibliographystyle{plain}
\bibliography{references} % Replace 'references' with the name of your .bib file

\end{document}
